{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELO or Year init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_or_year = 2010"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memory_fraction = 0.9\n",
    "\n",
    "torch.cuda.set_per_process_memory_fraction(gpu_memory_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # using cuda\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_size = 10000\n",
    "\n",
    "X : torch.Tensor = torch.load('./large_data/X_tensor_'+str(elo_or_year)+'.pt')#[:data_size]\n",
    "Y : torch.Tensor = torch.load('./large_data/Y_tensor_'+str(elo_or_year)+'.pt')#[:data_size]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# Define the split percentages\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Calculate the sizes of each split\n",
    "total_size = len(X)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "print(total_size, train_size, val_size)\n",
    "\n",
    "split_index = int(train_ratio * len(X))\n",
    "\n",
    "train_batch_size = 6000\n",
    "val_batch_size = 1000\n",
    "\n",
    "# train_batch_size = train_size//4\n",
    "# val_batch_size = val_size//2\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_subset_X = X[:split_index]\n",
    "val_subset_X = X[split_index:]\n",
    "train_loader_X = DataLoader(train_subset_X, batch_size=train_batch_size, shuffle=False)\n",
    "val_loader_X = DataLoader(val_subset_X, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "train_subset_Y = Y[:split_index]\n",
    "val_subset_Y = Y[split_index:]\n",
    "train_loader_Y = DataLoader(train_subset_Y, batch_size=train_batch_size, shuffle=False)\n",
    "val_loader_Y = DataLoader(val_subset_Y, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "# Get their size\n",
    "total_train_batches = len(train_loader_X)\n",
    "total_val_batches = len(val_loader_X)\n",
    "\n",
    "print(total_train_batches)\n",
    "print(total_val_batches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neuro_gambit().to(device)\n",
    "print('Model initalized')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/'+str(model._get_name())+'_'+str(elo_or_year)+'.pt')) # it takes the loaded dictionary, not the path file itself\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning params init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_epochs = 600\n",
    "\n",
    "criterion = nn.MSELoss() # MSE function\n",
    "# optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate) # stochastic gradient descent function\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate) # way better performance with AdamW than SGD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_val_loss_found = False\n",
    "for epoch in range(n_epochs):\n",
    "    batch = 0\n",
    "    last_train_loss = 0\n",
    "    if not last_val_loss_found: last_val_loss = -1\n",
    "\n",
    "    for train_X, train_Y in zip(train_loader_X, train_loader_Y):\n",
    "        train_X = train_X.to(device)\n",
    "        train_Y = train_Y.to(device)\n",
    "        # forward\n",
    "        y_preds = model(train_X) # will output a tuple of 5 tensors\n",
    "\n",
    "        # seperating the Y\n",
    "        Y1 = train_Y[:, :8]\n",
    "        Y2 = train_Y[:, 8:16]\n",
    "        Y3 = train_Y[:, 16:24]\n",
    "        Y4 = train_Y[:, 24:32]\n",
    "        Y5 = train_Y[:, 32:]\n",
    "\n",
    "        Y_list = [Y1,Y2,Y3,Y4,Y5]\n",
    "\n",
    "        train_loss = 0\n",
    "        for i in range(len(y_preds)): # calculating the loss per tensor\n",
    "            y_pred = y_preds[i]\n",
    "            train_loss += criterion(y_pred, Y_list[i])\n",
    "        last_train_loss = train_loss\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        print(f'Train: Epoch [{epoch+1}/{n_epochs}], Batch [{batch+1}/{total_train_batches}], Train Loss: {last_train_loss:.4f}, Val Loss: {last_val_loss:.4f}', end='\\r')\n",
    "        batch +=1\n",
    "\n",
    "    batch = 0\n",
    "    last_val_loss_found = True\n",
    "    for val_X, val_Y in zip(val_loader_X, val_loader_Y):\n",
    "        val_X = val_X.to(device)\n",
    "        val_Y = val_Y.to(device)\n",
    "        # forward\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(val_X) # will output a tuple of 5 tensors\n",
    "\n",
    "            # seperating the Y\n",
    "            Y1 = val_Y[:, :8]\n",
    "            Y2 = val_Y[:, 8:16]\n",
    "            Y3 = val_Y[:, 16:24]\n",
    "            Y4 = val_Y[:, 24:32]\n",
    "            Y5 = val_Y[:, 32:]\n",
    "\n",
    "            Y_list = [Y1,Y2,Y3,Y4,Y5]\n",
    "\n",
    "            val_loss = 0\n",
    "            for i in range(len(y_preds)): # calculating the loss per tensor\n",
    "                y_pred = y_preds[i]\n",
    "                val_loss += criterion(y_pred, Y_list[i])\n",
    "            last_val_loss = val_loss\n",
    "\n",
    "        print(f'Valid: Epoch [{epoch+1}/{n_epochs}], Batch [{batch+1}/{total_val_batches}], Train Loss: {last_train_loss:.4f}, Val Loss: {last_val_loss:.4f}', end='\\r')\n",
    "        batch+=1\n",
    "\n",
    "    if epoch == 300:\n",
    "        torch.save(model.state_dict(), './models/'+str(model._get_name())+'_'+str(elo_or_year)+'.pt')\n",
    "        print(f'Model saved at Train Loss: {last_train_loss:.4f}, Val Loss: {last_val_loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), './models/'+str(model._get_name())+'_'+str(elo_or_year)+'.pt')\n",
    "print('Model saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
